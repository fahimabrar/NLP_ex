{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from string import digits\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = open(\"example.txt\",'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the text file we will use for doing different text processsing operation. We may use unneces'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the frist 100 characters to see of the data is loaded properly\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the string data into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the text file we will use for doing different text processsing operation. we may use unnecessary punctuations so that 'ol[]p] we can remove them later with python code.\n",
      "this2983 is a [] ver,9869y noi*(^(%)sy sen(*&8p,..tence that contains di398475ffernt pucn^&*6tuations and numbers. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data =  data.lower()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the punctuation from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the text file we will use for doing different text processsing operation we may use unnecessary punctuations so that olp we can remove them later with python code\n",
      "this2983 is a  ver9869y noisy sen8ptence that contains di398475ffernt pucn6tuations and numbers \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_punctuation = str.maketrans('', '', string.punctuation)\n",
    "data = data.translate(remove_punctuation)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function structures of maketrans\n",
    "maketrans(x, y, z)\n",
    "- x - Required. If only one parameter is specified, this has to be a dictionary describing how to perform the replace.\n",
    "    If two or more parameters are specified, this parameter has to be a string specifying the characters you want to replace.\n",
    "- y - Optional. A string with the same length as parameter x. \n",
    "    Each character in the first parameter will be replaced with the corresponding character in this string.\n",
    "    \n",
    "- z- Optional. A string describing which characters to remove from the original string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing digits from the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the text file we will use for doing different text processsing operation we may use unnecessary punctuations so that olp we can remove them later with python code\n",
      "this is a  very noisy senptence that contains differnt pucntuations and numbers \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "data = data.translate(remove_digits)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting the word frequency we will use counter from the \"collections\" library that we imported before\n",
    "x = Counter(data.split()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 3),\n",
       " ('this', 2),\n",
       " ('is', 2),\n",
       " ('text', 2),\n",
       " ('use', 2),\n",
       " ('that', 2),\n",
       " ('the', 1),\n",
       " ('file', 1),\n",
       " ('will', 1),\n",
       " ('for', 1),\n",
       " ('doing', 1),\n",
       " ('different', 1),\n",
       " ('processsing', 1),\n",
       " ('operation', 1),\n",
       " ('may', 1),\n",
       " ('unnecessary', 1),\n",
       " ('punctuations', 1),\n",
       " ('so', 1),\n",
       " ('olp', 1),\n",
       " ('can', 1),\n",
       " ('remove', 1),\n",
       " ('them', 1),\n",
       " ('later', 1),\n",
       " ('with', 1),\n",
       " ('python', 1),\n",
       " ('code', 1),\n",
       " ('a', 1),\n",
       " ('very', 1),\n",
       " ('noisy', 1),\n",
       " ('senptence', 1),\n",
       " ('contains', 1),\n",
       " ('differnt', 1),\n",
       " ('pucntuations', 1),\n",
       " ('and', 1),\n",
       " ('numbers', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the counter into dictionary\n",
    "x = dict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['we', 'this', 'is', 'text', 'use', 'that', 'the', 'file', 'will', 'for', 'doing', 'different', 'processsing', 'operation', 'may', 'unnecessary', 'punctuations', 'so', 'olp', 'can', 'remove', 'them', 'later', 'with', 'python', 'code', 'a', 'very', 'noisy', 'senptence', 'contains', 'differnt', 'pucntuations', 'and', 'numbers'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the unique words we have\n",
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the keys into list to get the vocabulary list\n",
    "vocabulary_list = list(x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the stopwords from the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the stopword list from the nltk library stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the text file we will use for doing different text processsing operation we may use unnecessary punctuations so that olp we can remove them later with python code\\nthis is a  very noisy senptence that contains differnt pucntuations and numbers \\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'file',\n",
       " 'use',\n",
       " 'different',\n",
       " 'text',\n",
       " 'processsing',\n",
       " 'operation',\n",
       " 'may',\n",
       " 'use',\n",
       " 'unnecessary',\n",
       " 'punctuations',\n",
       " 'olp',\n",
       " 'remove',\n",
       " 'later',\n",
       " 'python',\n",
       " 'code',\n",
       " 'noisy',\n",
       " 'senptence',\n",
       " 'contains',\n",
       " 'differnt',\n",
       " 'pucntuations',\n",
       " 'numbers']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the stopwords from the string\n",
    "[w for w in data.split() if not w in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is the process of converting a word to its base form.\n",
    "The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"better\", pos = \"a\")\n",
    "# here pos = a as \"better\" is an adjective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of stemming in nltk library\n",
    "PorterStemmer is an older one, LancasterSetmmer is newer. But both of them serve very simillar purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre-programm'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem(\"pre-programmers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem(\"programmers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a src = \"https://www.linkedin.com/in/abrar-fahim/\">-Abrar Fahim</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
